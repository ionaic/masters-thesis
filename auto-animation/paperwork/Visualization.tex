
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                                                 %
%                           METHODS                               %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
% \specialhead{METHODS}
\chapter{VISUALIZATION}
\label{chapter:visualization}
In this chapter we motivate the need for good visualizations, as well as the difficulty of visualizing character animation in print format as well as video.  We then discuss techniques we utilized to visualize our data for presentation as well as for debugging and analysis.

% talk about instpiriations here instead of prev work
\section{Motivation and Inspiration}
\label{section:vis_insp}
Showing a motion in a static medium such as print presents numerous challenges.  The static image or images must convey a sense of time that is understandable, such that a viewer may intuit the direction and rate of movement.  Especially for a complex object such as a figure, occlusion can obstruct information, and prevent understanding of the motion of hidden portions of the body.  The projection of a 3D scene can also create similar issues as occlusion, creating ambiguity in depth and obscuring motions in some dimensions.

We drew from several sources for inspiration on how to visualize our results.  A video by KORB created for the CCTV Documentary Channel shows ``motion sculptures,'' in which the people in the scene leave trails of material as they move.  These sculptures very cleverly captured the movement of the body throughout the space of the video, creating aesthetically pleasing, if somewhat difficult to parse, visuals.

Another film of a similar nature is Choros by Michael Langan and Terah Maher.  Images of a single dancer follow her through her her movements, leaving a traceable pattern of movement.  This technique was inspired by chronophotography, a precursor to video which utilizes multiple successive photographs or multiple exposures on the same film to visualize movement of a figure or object.  These can be laid out in animation strips or superimposed to create a single image.

\section{Motion Visualization}
\label{section:motion_vis}
%For visualizing motion of a character or figure, there are a limited selection of different techniques.  Most common is a sequence of frames in which a character is posed, either in a still sequence or as a video.  As this is a final goal of our system, this is a valid visualization, but fails to provide a simple comparison between one animated sequence and another.  This is desirable for qualifying or quantifying performance of the system.  A sequence of still images is also space-consuming, which can be undesirable for print formats or even digital formats where length or size of document is an issue.

Markers were used to highlight motion of particular parts of the body, such as the pelvis or center of mass.  Other indicators placed on or around the figure can indicate other values, such as arrows to represent vectors of force.  This however can result in clutter within the images, scene, or frame of video, occluding or distraction from the primary animation.  Copies of the character could be left behind to produce an after image effect such as in the videos discussed in section \ref{section:vis_insp}.  We used these techniques in conjunction with each other, enabling and disabling them as the situation required.


\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{images/trails/trail-side.png}
	\caption[Marker trail visualization of motion]{Above is an example of the markers tracking joints.  With a high sample rate, a curve forms trailing along the path of the joint.  Markers were placed at a rate of 10 per second of simulation time.}
	\label{fig:marker_trails}
\end{figure}

Markers were implemented as camera-facing ``billboard'' planes with a texture that were spawned with a user-specified frequency, following an arbitrary joint of the character.  Each frame the orientation of the planes adjusts such that it faces the main active camera, allowing very little geometry to be used to produce an always visible visual to be placed in the scene.  We used one of these for each joint in the legs as well as one for the pelvis in order to track the paths of the joints.  This visualization was an interesting one to view, and gave a similar effect to motion sculptures, but was very difficult to understand without a reference to know which color of marker corresponded to which joint.  Even with knowledge of which joint followed which trail of markers, the visualization was difficult to understand, though it gave a good overview of the whole motion.  These marker trails are shown in Figure \ref{fig:marker_trails}.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/ghosts/side-sparse.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/ghosts/side-dense.png}
	\end{subfigure}
	\caption[Ghost image visualization]{Pictured above are examples of a ghost image visualization achieved by placing copies of the character model at a rate of 1 per 0.5s (pictured left) and 1 per 0.2s (pictured right).}
	\label{fig:ghost_vis}
\end{figure}

We used a ghost image visualization as well in 2 ways: leaving copies of the character behind at a user defined rate and layering collected frame data.  In the first method, we make a copy of only the model and necessary skeleton components, leaving out the extra data such as mass, constraints, and muscles used in our simulation, and match the positions and rotations of each of its joints to the character at the current time.  The ghosts use a semi-transparent material to help differentiate between them and the model, as well as to provide some clarity as to each ghost's pose and combat the issues of occlusion.  Examples of this visualization are shown in Figure \ref{fig:ghost_vis}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{images/k200kvaryingcomposite.png}
	\caption[Composite frame visualization]{An example of the composited frames visualization, in which several frames of the animation are layered on top of each other, and matte painted to produce a combined image with all frames superimposed.}
	\label{fig:composite_vis}
\end{figure}

An alternate method of forming the ghost image visualization was to layer numerous collected frames in an image editing program.  This method was very work intensive, requiring each layer to be matte painted by hand.  Algorithms and techniques in image processing and computer vision for automating this process, but for our purposes it was necessary to manually select the desired region in each image that should be visible in the final combined image.  To reduce the negative effects of occlusion, layers above the first were given an opacity of $75\%$.  Though work intensive, this produced an excellent visual for still media to show the path of the entire motion, but was a poor visual in many cases for showing detail of the movement as images often occlude each other.  Examples of this visualization are shown in Figure \ref{fig:composite_vis} and in Figure \ref{fig:complex_scene}.  As a compliment to this visual, we used animation strips, in which the frames were simply presented adjacent to each other in order from left to right.  These strips are also found in the data tables presented in Section \ref{section:image_results} and in Figure \ref{fig:complex_scene}.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/gizmos1.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/gizmos2.png}
	\end{subfigure}
	\caption[Screenshot of Gizmos used for debug visualizations in \unity{}]{Pictured above are screenshots of Gizmos in the \unity{} Editor.  The green points illustrate the sample field taken at the beginning of the jump, while the gray lines show the energy measured at this sample.  The rays beginning at the player's pelvis show the magnitude and direction of the acceleration (magenta) and velocity (blue) of the character.  The green line at the player's feet shows the displacement from the start position to the destination, and the cyan line starting at the player's pelvis shows the calculated kinetic energy.  At right, a closer view of the samples is shown to show the blue dots which outline the balanced region which the samples were restricted to.  The character is distanced from these samples as the Gizmos are drawn at the character's start position, and the character in this scene has completed its jump and is at the destination position.  The orange particle is a marker placed at the start position.}
	\label{fig:gizmo_vis}
\end{figure}

For debugging visuals, we used a feature in \unity{} called Gizmos, which allowed debug drawing of primitive shapes.  We used small spheres of various colors to show sample positions, target positions for the IK solver, corners of the supporting polygon, and the position of the center of mass.  Rays were used to visualize velocity, acceleration, distance to the destination, and value of the samples.  A screenshot of our Gizmos active for an energy based simulation are shown in Figure \ref{fig:gizmo_vis}.

\begin{figure}[ht]
	\centering
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/handles1.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{images/handles2.png}
	\end{subfigure}
	\caption[Screenshot of Handles used for setting and visualizing joint constraints in \unity{}]{Shown above are Handles, a tool similar to Gizmos but with the addition of changing a value.  In this case, the Handles affect the minimum and maximum rotation for the joints.  Handles are only visible when the corresponding object is selected by the user, reducing clutter.  All three Handles are shown in the left image, allowing the user to set the constraints for pitch (red), yaw (green), and roll (blue) as the pelvis is set to allow rotations about all three axes.  At right, we show the Handle for adjusting the constraints of the left knee, which is only able to rotate about the x-axis (pitch).}
	\label{fig:handle_vis}
\end{figure}

Similar to the Gizmos, we utilized a feature called Handles to ease setting and visualization of the joint constraints on the skeleton.  Unlike a Gizmo, a Handle can be manipulated by the user to affect values in the simulation before run time.  As shown in Figure \ref{fig:handle_vis}, three handles were used to adjust pitch, yaw, and roll, color coded as red, green, and blue.  Colors were chosen to correspond to the colors of the reference axes placed in the scene to aid the user, showing the red, green, and blue handles as limiting rotation about the x, y, and z axes respectively.

\section{Summary}
In this chapter we discussed some difficulties in visualizing animations in both animated and non-animated settings.  We presented some sources of inspiration and discussed the different methods we used to visualize data for presentation, analysis, and debugging.  Methods we used for analysis and presentation included trails of markers, ghost images created by duplicating the player model in the scene, layering frames to create a single image, and animation strips.  Our debugging visualizations took advantage of \unity{} utilities, using Gizmos and Handles to allow the user to see information about the simulation, as well as to more easily adjust constraints on the skeleton.
\label{section:vis_summary}
